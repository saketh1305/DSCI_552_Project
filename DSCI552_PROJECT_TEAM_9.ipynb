{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330d325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import PIL\n",
    "import pillow_avif\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bc1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0135e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Landmarks_v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91d8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[]\n",
    "landmarks=[]\n",
    "for i in os.listdir(data_dir):\n",
    "    if i!='.DS_Store':\n",
    "        categories.append(i)\n",
    "for i in categories:\n",
    "    for landmark in os.listdir(os.path.join(data_dir,i)):\n",
    "        landmarks.append(landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42cf069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "landmark_labels = []\n",
    "category_labels = []\n",
    "landmark_names = []\n",
    "c=0\n",
    "for category_idx, category in enumerate(categories):\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    landmarks = os.listdir(category_dir)\n",
    "    for landmark_idx, landmark in enumerate(landmarks):\n",
    "        landmark_dir = os.path.join(category_dir, landmark)\n",
    "        if landmark!='.DS_Store':\n",
    "            for img in os.listdir(landmark_dir):\n",
    "                img_path = os.path.join(landmark_dir, img)\n",
    "                img_array = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img_array)\n",
    "                image_data.append(img_array)\n",
    "                landmark_labels.append(c)\n",
    "\n",
    "                category_labels.append(category_idx)\n",
    "                landmark_names.append(landmark)\n",
    "            c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eaddd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagodas 0\n",
      "NeoClassical 1\n",
      "Pyramids 2\n",
      "Modern 3\n",
      "Mughal 4\n",
      "Gothic 5\n"
     ]
    }
   ],
   "source": [
    "for category_idx, category in enumerate(categories):\n",
    "    print(category,category_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045c7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TianningTemplePagoda', 'ThienMuPagoda', 'GiantWildGoosePagoda', 'ShwedagonPagoda', 'FogongTemplePagoda', 'Buckingham Palace', 'Concertgebouw', 'Panth‚on', 'Academy of Athens', 'Ripon Building', 'Pyramid of Giza', 'Pyramid of Djoser', 'Santa Cecilia Acatitlan Pyramid', 'El Castillo, Chichen Itza', 'Louvre Pyramid', 'Hallgr¡mskirkja', 'Chrysler Building', 'CCTV Headquarters', 'eiffel', 'Cathedral of Bras”lia', 'Tomb of I_timad-ud-Daulah', 'Taj Mahal', 'Tomb of Akbar', 'Jama Masjid', 'Bibi Ka Maqbara', 'St.VitusCathedral', 'MilanCathedral', 'ChartresCathedral', 'CologneCathedral', 'Notre-DameCathedral']\n"
     ]
    }
   ],
   "source": [
    "landmark_list=[]\n",
    "for i in range(len(landmark_labels)):\n",
    "    landmark_list.append((landmark_names[i],landmark_labels[i]))\n",
    "\n",
    "set_land = set(landmark_list)\n",
    "land_list=[0 for i in range(30)]\n",
    "for i in set_land:\n",
    "    land_list[i[1]]=i[0]\n",
    "print(land_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46524e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_landmark_train, y_landmark_test, y_category_train, y_category_test, landmarks_train, landmarks_test = train_test_split(\n",
    "    image_data, landmark_labels, category_labels, landmark_names, test_size=0.2, random_state=42, stratify=landmark_labels\n",
    ")\n",
    "\n",
    "num_category_classes = 6\n",
    "num_landmark_classes = 30\n",
    "\n",
    "y_category_train = to_categorical(y_category_train, num_classes=num_category_classes)\n",
    "y_category_test = to_categorical(y_category_test, num_classes=num_category_classes)\n",
    "\n",
    "y_landmark_train = to_categorical(y_landmark_train, num_classes=num_landmark_classes)\n",
    "y_landmark_test = to_categorical(y_landmark_test, num_classes=num_landmark_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de4d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "#from tensorflow.keras.applications.vgg_preprocess import preprocess_input as vgg_preprocess\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)\n",
    "image_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
    "                               rotation_range=20, \n",
    "                               width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, \n",
    "                               rescale=1/255,\n",
    "                               shear_range=0.1,\n",
    "                               zoom_range=0.1,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb20eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen_category = image_gen.flow(\n",
    "        np.array(X_train),\n",
    "        np.array(y_category_train)\n",
    "    )\n",
    "\n",
    "test_data_gen_category = image_gen.flow(\n",
    "    np.array(X_test),\n",
    "    np.array(y_category_test)\n",
    ")\n",
    "\n",
    "# Create data generators for train and test sets for landmarks\n",
    "train_data_gen_landmark = image_gen.flow(\n",
    "    np.array(X_train),\n",
    "    np.array(y_landmark_train)\n",
    ")\n",
    "\n",
    "test_data_gen_landmark = image_gen.flow(\n",
    "    np.array(X_test),\n",
    "    np.array(y_landmark_test),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34cdb11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from category_tuning/category_model_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    num_layers_to_unfreeze = hp.Int(\"num_layers_to_unfreeze\", min_value=1, max_value=5, step=1)\n",
    "    for layer in vgg16_model.layers[:-num_layers_to_unfreeze]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = vgg16_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hp.Int(\"dense_1_units\", min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    x = Dropout(hp.Float(\"dropout_1_rate\", min_value=0.3, max_value=0.7, step=0.1))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Dense(hp.Int(\"dense_2_units\", min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    x = Dropout(hp.Float(\"dropout_2_rate\", min_value=0.3, max_value=0.7, step=0.1))(x)\n",
    "    x = Dense(6, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=vgg16_model.input, outputs=x)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=Adam(hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"LOG\")),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of different hyperparameter configurations to try\n",
    "    executions_per_trial=1,  # Number of trainings per trial\n",
    "    directory='category_tuning',\n",
    "    project_name='category_model_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc013f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 03m 18s]\n",
      "val_accuracy: 0.7142857313156128\n",
      "\n",
      "Best val_accuracy So Far: 0.9047619104385376\n",
      "Total elapsed time: 00h 03m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Best dense_1_units: 768\n",
      "Best dropout_1_rate: 0.4\n",
      "Best dense_2_units: 2048\n",
      "Best dropout_2_rate: 0.5\n",
      "Best learning_rate: 0.0002995853178427231\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 13.8047 - accuracy: 0.4077 - val_loss: 0.6351 - val_accuracy: 0.9048\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 1.8967 - accuracy: 0.8155 - val_loss: 0.5585 - val_accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 1.3356 - accuracy: 0.9137 - val_loss: 0.7620 - val_accuracy: 0.9048\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.5259 - accuracy: 0.9583 - val_loss: 0.3196 - val_accuracy: 0.9405\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.3562 - accuracy: 0.9643 - val_loss: 0.4968 - val_accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.3373 - accuracy: 0.9762 - val_loss: 1.4100 - val_accuracy: 0.8929\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.0319 - accuracy: 0.9940 - val_loss: 1.1281 - val_accuracy: 0.9405\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.2755 - accuracy: 0.9821 - val_loss: 0.9738 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.0729 - accuracy: 0.9940 - val_loss: 1.0939 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.1372 - accuracy: 0.9792 - val_loss: 0.9244 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X_train_category = train_data_gen_category.x\n",
    "y_train_category = train_data_gen_category.y\n",
    "X_test_category = test_data_gen_category.x\n",
    "y_test_category = test_data_gen_category.y\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=2, verbose=1)\n",
    "tuner.search(train_data_gen_category, validation_data=test_data_gen_category, epochs=5, callbacks=[early_stop])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Best dense_1_units: {best_hps.get('dense_1_units')}\")\n",
    "print(f\"Best dropout_1_rate: {best_hps.get('dropout_1_rate')}\")\n",
    "print(f\"Best dense_2_units: {best_hps.get('dense_2_units')}\")\n",
    "print(f\"Best dropout_2_rate: {best_hps.get('dropout_2_rate')}\")\n",
    "print(f\"Best learning_rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_category,y_train_category, validation_data=(X_test_category,y_test_category), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f621aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 2s/step - loss: 0.5415 - accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.541456937789917, 0.9285714030265808]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_category, y_test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93aed477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 27s 2s/step\n",
      "3/3 [==============================] - 7s 2s/step\n"
     ]
    }
   ],
   "source": [
    "X_train_landmark = train_data_gen_landmark.x\n",
    "y_train_landmark = train_data_gen_landmark.y\n",
    "X_test_landmark = test_data_gen_landmark.x\n",
    "y_test_landmark = test_data_gen_landmark.y\n",
    "\n",
    "# Prepare the category predictions for the train dataset\n",
    "category_predictions_train = model.predict(X_train_landmark)\n",
    "\n",
    "# Prepare the category predictions for the test dataset\n",
    "category_predictions_test = model.predict(X_test_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a71279ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_landmark_model(hp):\n",
    "    # Load the base VGG16 model for landmark classification\n",
    "    vgg16_landmark_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    num_layers_to_unfreeze = hp.Int(\"num_layers_to_unfreeze_landmark\", min_value=1, max_value=5, step=1)\n",
    "    for layer in vgg16_landmark_base.layers[:-num_layers_to_unfreeze]:\n",
    "        layer.trainable = False\n",
    "#     for layer in vgg16_landmark_base.layers[:-3]:\n",
    "#         layer.trainable = False\n",
    "    \n",
    "    # Extract the output of the base VGG16 model for landmark classification\n",
    "    vgg_landmark_output = vgg16_landmark_base.output\n",
    "\n",
    "    # Flatten the VGG16 landmark output\n",
    "    feature_vector_landmark = Flatten(name='flatten_landmark')(vgg_landmark_output)\n",
    "\n",
    "    # Use the category predictions as input\n",
    "    category_input_landmark = Input(shape=(6,), name='category_input_landmark')\n",
    "\n",
    "    # Concatenate the feature vector and the category input\n",
    "    merged_input_landmark = Concatenate(name=\"concatenate_landmark\")([feature_vector_landmark, category_input_landmark])\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    units = hp.Int('units', min_value=512, max_value=2048, step=256)\n",
    "    x_landmark = Dense(units, activation='relu')(merged_input_landmark)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    x_landmark = Dropout(dropout_rate)(x_landmark)\n",
    "    \n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    units = hp.Int('units2', min_value=512, max_value=2048, step=256)\n",
    "    x_landmark = Dense(units, activation='relu')(x_landmark)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    dropout_rate = hp.Float('dropout_rate2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    x_landmark = Dropout(dropout_rate)(x_landmark)\n",
    "\n",
    "    landmark_output = Dense(30, activation='softmax')(x_landmark)\n",
    "\n",
    "    # Create the landmark model\n",
    "    landmark_model = Model(inputs=[vgg16_landmark_base.input, category_input_landmark], outputs=landmark_output)\n",
    "\n",
    "    landmark_model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return landmark_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dca835fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from monday_mrng_tuner/landmark_model_tuning/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers_to_unfreeze_landmark (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 2048, 'step': 256, 'sampling': 'linear'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "units2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 2048, 'step': 256, 'sampling': 'linear'}\n",
      "dropout_rate2 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_landmark_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=15,  # Number of different hyperparameter configurations to try\n",
    "    executions_per_trial=1,  # Number of trainings per trial\n",
    "    directory='monday_mrng_tuner',\n",
    "    project_name='landmark_model_tuning'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Start the search for the best hyperparameters\n",
    "tuner.search(\n",
    "    [X_train_landmark, category_predictions_train],\n",
    "    y_train_landmark,\n",
    "    epochs=10,\n",
    "    validation_data=([X_test_landmark, category_predictions_test], y_test_landmark)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc45da88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_landmark (Flatten)     (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " category_input_landmark (Input  [(None, 6)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_landmark (Concaten  (None, 25094)       0           ['flatten_landmark[0][0]',       \n",
      " ate)                                                             'category_input_landmark[0][0]']\n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 768)          19272960    ['concatenate_landmark[0][0]']   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 768)         3072        ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2048)         1574912     ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 2048)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 30)           61470       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,627,102\n",
      "Trainable params: 20,910,878\n",
      "Non-trainable params: 14,716,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_landmark_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_landmark_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4be60fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 2s/step - loss: 0.4183 - accuracy: 0.9048\n",
      "Test loss:  0.4182627499103546\n",
      "Test accuracy:  0.9047619104385376\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "results = best_landmark_model.evaluate([X_test_landmark, category_predictions_test], y_test_landmark)\n",
    "print(\"Test loss: \", results[0])\n",
    "print(\"Test accuracy: \", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c16a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('category_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55715f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_landmark_model.save('landmark_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32be801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bd22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
